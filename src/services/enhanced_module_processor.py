#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ARQV30 Enhanced v3.0 - Enhanced Module Processor
Processador aprimorado de m√≥dulos com IA
"""

import os
import logging
import asyncio
import json
from typing import Dict, List, Any
from datetime import datetime
from pathlib import Path

# Import do Enhanced AI Manager
from services.enhanced_ai_manager import enhanced_ai_manager
from services.auto_save_manager import salvar_etapa, salvar_erro
from services.predictive_analytics_service import predictive_analytics_service # Import adicionado
from modules.cpl_creator import create_devastating_cpl_protocol

logger = logging.getLogger(__name__)

class EnhancedModuleProcessor:
    """Processador aprimorado de m√≥dulos"""

    def __init__(self):
        """Inicializa o processador"""
        self.ai_manager = enhanced_ai_manager

        # Lista completa dos m√≥dulos (incluindo o novo m√≥dulo CPL)
        self.modules_config = {
            "anti_objecao": {
                "title": "Sistema Anti-Obje√ß√£o",
                "description": "Sistema completo para antecipar e neutralizar obje√ß√µes",
                "use_active_search": False,
                "type": "standard"
            },
            "avatars": {
                "title": "Avatares do P√∫blico-Alvo",
                "description": "Personas detalhadas do p√∫blico-alvo",
                "use_active_search": False,
                "type": "standard"
            },
            "concorrencia": {
                "title": "An√°lise Competitiva",
                "description": "An√°lise completa da concorr√™ncia",
                "use_active_search": True,
                "type": "standard"
            },
            "drivers_mentais": {
                "title": "Drivers Mentais",
                "description": "Gatilhos psicol√≥gicos e drivers de compra",
                "use_active_search": False,
                "type": "standard"
            },
            "funil_vendas": {
                "title": "Funil de Vendas",
                "description": "Estrutura completa do funil de vendas",
                "use_active_search": False,
                "type": "standard"
            },
            "insights_mercado": {
                "title": "Insights de Mercado",
                "description": "Insights profundos sobre o mercado",
                "use_active_search": True,
                "type": "standard"
            },
            "palavras_chave": {
                "title": "Estrat√©gia de Palavras-Chave",
                "description": "Estrat√©gia completa de SEO e palavras-chave",
                "use_active_search": False,
                "type": "standard"
            },
            "plano_acao": {
                "title": "Plano de A√ß√£o",
                "description": "Plano de a√ß√£o detalhado e execut√°vel",
                "use_active_search": False,
                "type": "standard"
            },
            "posicionamento": {
                "title": "Estrat√©gia de Posicionamento",
                "description": "Posicionamento estrat√©gico no mercado",
                "use_active_search": False,
                "type": "standard"
            },
            "pre_pitch": {
                "title": "Estrutura de Pr√©-Pitch",
                "description": "Estrutura de pr√©-venda e engajamento",
                "use_active_search": False,
                "type": "standard"
            },
            "predicoes_futuro": {
                "title": "Predi√ß√µes de Mercado",
                "description": "Predi√ß√µes e tend√™ncias futuras",
                "use_active_search": True,
                "type": "standard"
            },
            "provas_visuais": {
                "title": "Sistema de Provas Visuais",
                "description": "Provas visuais e sociais",
                "use_active_search": False,
                "type": "standard"
            },
            "metricas_conversao": {
                "title": "M√©tricas de Convers√£o",
                "description": "KPIs e m√©tricas de convers√£o",
                "use_active_search": False,
                "type": "standard"
            },
            "estrategia_preco": {
                "title": "Estrat√©gia de Precifica√ß√£o",
                "description": "Estrat√©gia de pre√ßos e monetiza√ß√£o",
                "use_active_search": False,
                "type": "standard"
            },
            "canais_aquisicao": {
                "title": "Canais de Aquisi√ß√£o",
                "description": "Canais de aquisi√ß√£o de clientes",
                "use_active_search": False,
                "type": "standard"
            },
            "cronograma_lancamento": {
                "title": "Cronograma de Lan√ßamento",
                "description": "Cronograma detalhado de lan√ßamento",
                "use_active_search": False,
                "type": "standard"
            },
            "cpl_completo": {
                "title": "Protocolo Integrado de CPLs Devastadores",
                "description": "Protocolo completo para cria√ß√£o de sequ√™ncia de 4 CPLs de alta performance",
                "use_active_search": True,
                "type": "specialized",
                "requires": ["sintese_master", "avatar_data", "contexto_estrategico", "dados_web"]
            }
        }

        logger.info("üöÄ Enhanced Module Processor inicializado")

    async def generate_all_modules(self, session_id: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Gera todos os m√≥dulos (16 padr√£o + 1 especializado CPL)"""
        logger.info(f"üöÄ Iniciando gera√ß√£o de todos os m√≥dulos para sess√£o: {session_id}")

        # Carrega dados base
        base_data = self._load_base_data(session_id)
        # Adiciona insights iniciais do contexto, se existirem
        if context and "initial_predictive_insights" in context:
            base_data["initial_predictive_insights"] = context["initial_predictive_insights"]
            logger.info("Insights preditivos iniciais adicionados ao base_data para m√≥dulos.")

        results = {
            "session_id": session_id,
            "successful_modules": 0,
            "failed_modules": 0,
            "modules_generated": [],
            "modules_failed": [],
            "total_modules": len(self.modules_config)
        }

        # Cria diret√≥rio de m√≥dulos
        modules_dir = Path(f"analyses_data/{session_id}/modules")
        modules_dir.mkdir(parents=True, exist_ok=True)

        # Gera cada m√≥dulo
        for module_name, config in self.modules_config.items():
            try:
                logger.info(f"üìù Gerando m√≥dulo: {module_name}")

                # Verifica se √© o m√≥dulo especializado CPL
                if module_name == "cpl_completo":
                    cpl_content = await create_devastating_cpl_protocol(
                        sintese_master=base_data.get("sintese_master", {}),
                        avatar_data=base_data.get("avatar_data", {}),
                        contexto_estrategico=base_data.get("contexto_estrategico", {}),
                        dados_web=base_data.get("dados_web", {}),
                        session_id=session_id
                    )
                    
                    cpl_json_path = modules_dir / f"{module_name}.json"
                    with open(cpl_json_path, "w", encoding="utf-8") as f:
                        json.dump(cpl_content, f, ensure_ascii=False, indent=2)
                    
                    cpl_md_content = self._format_cpl_content_to_markdown(cpl_content)
                    cpl_md_path = modules_dir / f"{module_name}.md"
                    with open(cpl_md_path, "w", encoding="utf-8") as f:
                        f.write(cpl_md_content)
                else:
                    # Gera conte√∫do do m√≥dulo padr√£o
                    prompt = self._get_module_prompt(module_name, config, base_data)
                    if config.get("use_active_search", False):
                        content = await self.ai_manager.generate_with_active_search(
                            prompt=prompt,
                            context=base_data.get("context", ""),
                            session_id=session_id
                        )
                    else:
                        content = await self.ai_manager.generate_text(
                            prompt=prompt
                        )

                    # Salva m√≥dulo padr√£o
                    module_path = modules_dir / f"{module_name}.md"
                    with open(module_path, "w", encoding="utf-8") as f:
                        f.write(content)

                results["successful_modules"] += 1
                results["modules_generated"].append(module_name)

                logger.info(f"‚úÖ M√≥dulo {module_name} gerado com sucesso")

            except Exception as e:
                logger.error(f"‚ùå Erro ao gerar m√≥dulo {module_name}: {e}")
                salvar_erro(f"modulo_{module_name}", e, contexto={"session_id": session_id})
                results["failed_modules"] += 1
                results["modules_failed"].append({
                    "module": module_name,
                    "error": str(e)
                })

        # Gera relat√≥rio consolidado
        await self._generate_consolidated_report(session_id, results)

        logger.info(f"‚úÖ Gera√ß√£o conclu√≠da: {results["successful_modules"]}/{results["total_modules"]} m√≥dulos")

        return results

    def _load_base_data(self, session_id: str) -> Dict[str, Any]:
        """Carrega dados base da sess√£o"""
        try:
            session_dir = Path(f"analyses_data/{session_id}")

            # Carrega s√≠nteses
            synthesis_data = {}
            for synthesis_file in session_dir.glob("sintese_*.json"):
                try:
                    with open(synthesis_file, "r", encoding="utf-8") as f:
                        synthesis_data[synthesis_file.stem] = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar s√≠ntese {synthesis_file}: {e}")

            # Carrega relat√≥rio de coleta
            coleta_content = ""
            coleta_file = session_dir / "relatorio_coleta.md"
            if coleta_file.exists():
                with open(coleta_file, "r", encoding="utf-8") as f:
                    coleta_content = f.read()

            # Carrega dados espec√≠ficos para o m√≥dulo CPL
            sintese_master = {}
            avatar_data = {}
            contexto_estrategico = {}
            dados_web = {}
            
            # Tenta carregar a s√≠ntese master
            sintese_master_file = session_dir / "sintese_master_synthesis.json"
            if sintese_master_file.exists():
                try:
                    with open(sintese_master_file, "r", encoding="utf-8") as f:
                        sintese_master = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar s√≠ntese master: {e}")
            
            # Tenta carregar dados do avatar
            avatar_file = session_dir / "avatar_detalhado.json"
            if avatar_file.exists():
                try:
                    with open(avatar_file, "r", encoding="utf-8") as f:
                        avatar_data = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar dados do avatar: {e}")
            
            # Tenta carregar contexto estrat√©gico
            contexto_file = session_dir / "contexto_estrategico.json"
            if contexto_file.exists():
                try:
                    with open(contexto_file, "r", encoding="utf-8") as f:
                        contexto_estrategico = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar contexto estrat√©gico: {e}")
            
            # Tenta carregar dados da web
            web_data_file = session_dir / "dados_pesquisa_web.json"
            if web_data_file.exists():
                try:
                    with open(web_data_file, "r", encoding="utf-8") as f:
                        dados_web = json.load(f)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao carregar dados da web: {e}")

            return {
                "synthesis_data": synthesis_data,
                "coleta_content": coleta_content,
                "context": f"Dados de s√≠ntese: {len(synthesis_data)} arquivos. Relat√≥rio de coleta: {len(coleta_content)} caracteres.",
                "sintese_master": sintese_master,
                "avatar_data": avatar_data,
                "contexto_estrategico": contexto_estrategico,
                "dados_web": dados_web
            }

        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados base: {e}")
            return {
                "synthesis_data": {}, 
                "coleta_content": "", 
                "context": "",
                "sintese_master": {},
                "avatar_data": {},
                "contexto_estrategico": {},
                "dados_web": {}
            }

    def _get_module_prompt(self, module_name: str, config: Dict[str, Any], base_data: Dict[str, Any]) -> str:
        """Gera prompt para um m√≥dulo espec√≠fico"""

        base_prompt = f"""# {config["title"]}

Voc√™ √© um especialista em {config["description"].lower()}.

## DADOS DISPON√çVEIS:
{base_data.get("context", "Dados limitados")}

## CONTEXTO DOS DADOS COLETADOS:
{base_data.get("coleta_content", "")[:1000]}...

"""
        # Adiciona insights preditivos ao prompt, se dispon√≠veis
        if "initial_predictive_insights" in base_data:
            base_prompt += f"\n## INSIGHTS PREDITIVOS INICIAIS:\n"
            for key, value in base_data["initial_predictive_insights"].items():
                base_prompt += f"- {key}: {value}\n"
            base_prompt += "\n"

        base_prompt += f"""## TAREFA:
Crie um m√≥dulo ultra-detalhado sobre {config["title"]} baseado nos dados coletados e nos insights preditivos.

## ESTRUTURA OBRIGAT√ìRIA:
1. **Resumo Executivo**
2. **An√°lise Detalhada**
3. **Estrat√©gias Espec√≠ficas**
4. **Implementa√ß√£o Pr√°tica**
5. **M√©tricas e KPIs**
6. **Cronograma de Execu√ß√£o**

## REQUISITOS:
- M√≠nimo 2000 palavras
- Dados espec√≠ficos do mercado brasileiro
- Estrat√©gias acion√°veis
- M√©tricas mensur√°veis
- Formato markdown profissional

Gere um conte√∫do extremamente detalhado e pr√°tico.
"""

        return base_prompt

    def _format_cpl_content_to_markdown(self, cpl_content: Dict[str, Any]) -> str:
        """Formata o conte√∫do do m√≥dulo CPL para Markdown"""
        try:
            markdown_content = f"""# {cpl_content.get("titulo", "Protocolo de CPLs Devastadores")}

{cpl_content.get("descricao", "")}

"""

            # Adiciona cada fase do protocolo
            fases = cpl_content.get("fases", {})
            for fase_key, fase_data in fases.items():
                markdown_content += f"## {fase_data.get("titulo", fase_key)}\n\n"
                markdown_content += f"**{fase_data.get("descricao", "")}**\n\n"
                
                # Adiciona se√ß√µes espec√≠ficas de cada fase
                if "estrategia" in fase_data:
                    markdown_content += f"### Estrat√©gia\n{fase_data["estrategia"]}\n\n"
                
                if "versoes_evento" in fase_data:
                    markdown_content += "### Vers√µes do Evento\n"
                    for versao in fase_data["versoes_evento"]:
                        markdown_content += f"- **{versao.get("nome_evento", "")}** ({versao.get("tipo", "")}): {versao.get("justificativa_psicologica", "")}\n"
                    markdown_content += "\n"
                
                if "teasers" in fase_data:
                    markdown_content += "### Teasers\n"
                    for teaser in fase_data["teasers"]:
                        markdown_content += f"- {teaser.get("texto", "")} (*{teaser.get("justificativa", "")}*)\n"
                    markdown_content += "\n"
                
                if "historia_transformacao" in fase_data:
                    ht = fase_data["historia_transformacao"]
                    markdown_content += "### Hist√≥ria de Transforma√ß√£o\n"
                    markdown_content += f"- **Antes**: {ht.get("antes", "")}\n"
                    markdown_content += f"- **Durante**: {ht.get("durante", "")}\n"
                    markdown_content += f"- **Depois**: {ht.get("depois", "")}\n\n"

                if "elementos_chave" in fase_data:
                    markdown_content += "### Elementos Chave\n"
                    for elemento in fase_data["elementos_chave"]:
                        markdown_content += f"- **{elemento.get("nome", "")}**: {elemento.get("descricao", "")}\n"
                    markdown_content += "\n"

                if "gatilhos_mentais" in fase_data:
                    markdown_content += "### Gatilhos Mentais Aplicados\n"
                    for gatilho in fase_data["gatilhos_mentais"]:
                        markdown_content += f"- **{gatilho.get("nome", "")}**: {gatilho.get("aplicacao", "")}\n"
                    markdown_content += "\n"

                if "exemplos_copy" in fase_data:
                    markdown_content += "### Exemplos de Copy\n"
                    for exemplo in fase_data["exemplos_copy"]:
                        markdown_content += f"- **{exemplo.get("tipo", "")}**: {exemplo.get("copy", "")}\n"
                    markdown_content += "\n"

            markdown_content += f"""## Conclus√£o

{cpl_content.get("conclusao", "")}

"""
            return markdown_content
        except Exception as e:
            logger.error(f"‚ùå Erro ao formatar conte√∫do CPL para Markdown: {e}")
            return f"Erro ao gerar CPL: {e}"

    async def _generate_consolidated_report(self, session_id: str, results: Dict[str, Any]):
        """Gera um relat√≥rio consolidado dos m√≥dulos gerados."""
        report_content = f"# Relat√≥rio Consolidado de Gera√ß√£o de M√≥dulos\n\n"
        report_content += f"**Sess√£o ID**: {session_id}\n"
        report_content += f"**Data de Gera√ß√£o**: {datetime.now().isoformat()}\n\n"
        report_content += f"**Total de M√≥dulos**: {results["total_modules"]}\n"
        report_content += f"**M√≥dulos Gerados com Sucesso**: {results["successful_modules"]}\n"
        report_content += f"**M√≥dulos com Falha**: {results["failed_modules"]}\n\n"

        if results["modules_generated"]:
            report_content += "## M√≥dulos Gerados com Sucesso\n"
            for module_name in results["modules_generated"]:
                report_content += f"- {self.modules_config[module_name]["title"]} ({module_name})\n"
            report_content += "\n"

        if results["modules_failed"]:
            report_content += "## M√≥dulos com Falha\n"
            for failed_module in results["modules_failed"]:
                report_content += f"- {self.modules_config[failed_module["module"]]["title"]} ({failed_module["module"]}) - Erro: {failed_module["error"]}\n"
            report_content += "\n"

        report_content += "## Detalhes dos M√≥dulos\n"
        for module_name in results["modules_generated"]:
            module_path = Path(f"analyses_data/{session_id}/modules/{module_name}.md")
            if module_path.exists():
                report_content += f"### {self.modules_config[module_name]["title"]}\n"
                report_content += f"[Ver M√≥dulo Completo]({module_path.name})\n\n"
            else:
                report_content += f"### {self.modules_config[module_name]["title"]} (Conte√∫do n√£o encontrado)\n\n"

        report_path = Path(f"analyses_data/{session_id}/relatorio_modulos_gerados.md")
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)
        logger.info(f"‚úÖ Relat√≥rio consolidado de m√≥dulos salvo em: {report_path}")

# Inst√¢ncia global
enhanced_module_processor = EnhancedModuleProcessor()


